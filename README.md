# Proyectos_Web_Scrapping
En este repositorio muestro los proyectos de Web Scrapping aplicados a diferentes objetivos y mediante diferentes t칠cnicas.

# **PROYECTO 1**:newspaper:
## Extraccion de datos desde el diario 치mbito financiero:

El proyecto busca poder obtener mediante el lenguaje de Python y Xpath la informaci칩n del reconocido diario de noticias 츼mbito Financiero. B치sicamente, mediante la utilizacion combinada de Python y Xpath se extrae el t칤tulo, el copete y el desarrollo de cada una de las noticias que se encuentran en el momento en la web del diario. Y una vez obtenida dicha informacion, se crea una carpeta con el nombre de la fecha de hoy (DD-MM-AAAA) dentro de la c칰al se guardan en diferentes archivos .txt toda la informacion citada anteriormente (t칤tulo, copete y desarrollo de la noticia), con lo cual esto resulta 칰til para poder realzar diferentes an치lisis de esa informaci칩n y tomar decisiones en base a ello. 
En segunda instancia se genera mediante la libreria WordCloud una nube de palabras eliminando mediante la libreria ntkl ( que corresponde al procesamiento del lenguaje natural) las palabras que hacen ruido y que no aportan al analisis. Finalmente con la nube de palabras que se observa se puede analizar cuales son las que mas aparecen en las noticias, siendo las mas grandes las que se observan con mayor frecuencia.

# **PROYECTO 2**:游뷣릖:
## Extraccion de datos Intituto Argentino de mercado de Capitales (IAMC) y Bolsas y Mercados Argentinos (BYMA):

El IAMC ( Instituto Argentino de Mercado de Capitales) presenta de forma diaria en formato pdf un informe completo del mercado correspondiente al d칤a de la fecha y adem치s cuelgan los informes de los 칰ltimos 30 d칤as, cada d칤a nuevo se elimina el 칰ltimo y se agrega el vigente. La web es la siguiente: https://www.iamc.com.ar/informediario/ . Esta informaci칩n que se encuentra en cada pdf es bastante completa. El objetivo es parsear mediante web scraping cada uno de esos pdf en lo que respecta a los bonos en d칩lares (que es la hoja 5 del pdf) y volcar esa informaci칩n en un data frame, al cual le hago limpieza y varias transformaciones para luego enviar esa informaci칩n al dataset de Alphacast. Algo parecido se realiza con los bonos en pesos, pero en lugar de utilizar la web dde IMAC, en este caso utilizo directamente el json que se encuentra en la web que utiliza javascript/ajax: https://www.byma.com.ar/wp-admin/admin-ajax.php?action=get_bonos. Luego arm칠 varios gr치ficos apoyados en estos 2 dataframes (bonos en pesos y en d칩lares). El c칩digo en la primera ejecuci칩n parsea todos los pdf, por eso demora aprox 60 segundos, pero luego, cada nuevo d칤a, solo parsea el 칰ltimo informe nuevo e incorpora esta informaci칩n 칰nicamente a la que se encuentra en el dataset de Alphacast, con lo cual la demora pasa a aprox. 10 segundos.
Pueden ver lo que fui cargando en Alphacast, con el jupyter notebook que les adjunto, en el repositorio N춿 1162, y dentro de este, el dataset de bonos en d칩lares es el N춿 7961 y el dataset de Bonos (Soberanos y Provinciales en pesos, U$D-Link, cupones PBI y ON) es el N춿 7973.
