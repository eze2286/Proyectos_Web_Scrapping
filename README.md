# Proyectos_Web_Scrapping
En este repositorio muestro los proyectos de Web Scrapping aplicados a diferentes objetivos y mediante diferentes técnicas.

# **PROYECTO 1**:newspaper:
## Extraccion de datos desde el diario ámbito financiero:

El proyecto busca poder obtener mediante el lenguaje de Python y Xpath la información del reconocido diario de noticias Ámbito Financiero. Básicamente, mediante la utilizacion combinada de Python y Xpath se extrae el título, el copete y el desarrollo de cada una de las noticias que se encuentran en el momento en la web del diario. Y una vez obtenida dicha informacion, se crea una carpeta con el nombre de la fecha de hoy (DD-MM-AAAA) dentro de la cúal se guardan en diferentes archivos .txt toda la informacion citada anteriormente (título, copete y desarrollo de la noticia), con lo cual esto resulta útil para poder realzar diferentes análisis de esa información y tomar decisiones en base a ello. 
En segunda instancia se genera mediante la libreria WordCloud una nube de palabras eliminando mediante la libreria ntkl ( que corresponde al procesamiento del lenguaje natural) las palabras que hacen ruido y que no aportan al analisis. Finalmente con la nube de palabras que se observa se puede analizar cuales son las que mas aparecen en las noticias, siendo las mas grandes las que se observan con mayor frecuencia.

# **PROYECTO 2**:🇦🇷:
## Extraccion de datos Intituto Argentino de mercado de Capitales (IAMC) y Bolsas y Mercados Argentinos (BYMA):

El IAMC ( Instituto Argentino de Mercado de Capitales) presenta de forma diaria en formato pdf un informe completo del mercado correspondiente al día de la fecha y además cuelgan los informes de los últimos 30 días, cada día nuevo se elimina el último y se agrega el vigente. La web es la siguiente: https://www.iamc.com.ar/informediario/ . Esta información que se encuentra en cada pdf es bastante completa. El objetivo es parsear mediante web scraping cada uno de esos pdf en lo que respecta a los bonos en dólares (que es la hoja 5 del pdf) y volcar esa información en un data frame, al cual le hago limpieza y varias transformaciones para luego enviar esa información al dataset de Alphacast. Algo parecido se realiza con los bonos en pesos, pero en lugar de utilizar la web dde IMAC, en este caso utilizo directamente el json que se encuentra en la web que utiliza javascript/ajax: https://www.byma.com.ar/wp-admin/admin-ajax.php?action=get_bonos. Luego armé varios gráficos apoyados en estos 2 dataframes (bonos en pesos y en dólares). El código en la primera ejecución parsea todos los pdf, por eso demora aprox 60 segundos, pero luego, cada nuevo día, solo parsea el último informe nuevo e incorpora esta información únicamente a la que se encuentra en el dataset de Alphacast, con lo cual la demora pasa a aprox. 10 segundos.
Pueden ver lo que fui cargando en Alphacast, con el jupyter notebook que les adjunto, en el repositorio N° 1162, y dentro de este, el dataset de bonos en dólares es el N° 7961 y el dataset de Bonos (Soberanos y Provinciales en pesos, U$D-Link, cupones PBI y ON) es el N° 7973.
